# v1.0.0 Research Handoff

## Recommendation

Implement Apply mode as a **standalone function** in a new `apply.py` module, plus CLI `apply` command. This decouples apply from generate, allowing users to apply cleaning functions at any time after generation.

## Key Decisions Made

1. **Standalone function vs method**: Standalone `apply_cleaning()` function. Decoupled from DataCleaner instance, matches CLI usage pattern.

2. **Import strategy**: Dynamic import using `importlib.util`. The generated `cleaning_functions.py` is valid Python with a `clean_data(data)` entrypoint.

3. **Streaming**: Stream JSONL and CSV (memory efficient). Batch JSON arrays and Parquet (format constraints).

4. **Output format**: Same as input format by default.

5. **Error handling**: Fail fast. A failing record indicates a bug in the generated function.

## Risks Identified

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Large JSON arrays exhaust memory | Low | Medium | Document limitation, recommend JSONL for large files |
| Cleaning function has bug | Medium | High | Validate with small subset first (user responsibility) |
| Import security | Low | Medium | File is generated by us, already AST-validated |

## Libraries Selected

None required - stdlib only (json, csv, importlib).

## Open Questions for User

1. **Text mode apply**: Should apply work on text files? The `clean_data(data)` function expects dict/record, not text string. Options:
   - Skip text mode (v1.0 is for structured data)
   - Wrap text as `{"text": "..."}` before apply
   - Require different function signature for text

   **Recommendation**: Skip text mode for v1.0. Apply is for structured data cleaning.

2. **Parquet output**: When input is Parquet, should output be Parquet or JSONL?
   - Parquet → Parquet (requires pyarrow)
   - Parquet → JSONL (no extra deps)

   **Recommendation**: Default to same format. User can override with `--output-format` flag.

Awaiting user approval before proceeding to contracts.
